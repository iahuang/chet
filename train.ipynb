{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def get_device() -> torch.device:\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42169964\n"
     ]
    }
   ],
   "source": [
    "from chet import Chet42, tokenize_board\n",
    "\n",
    "model = Chet42()\n",
    "model.to(device)\n",
    "print(model.get_n_params())\n",
    "\n",
    "tokenizer = lambda board: tokenize_board(board).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import chess\n",
    "import csv\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def load_dataset(\n",
    "    csv_file: str,\n",
    "    tokenizer: Callable[[chess.Board], torch.Tensor],\n",
    "    *,\n",
    "    limit: int | None = None,\n",
    "    skip_header: bool = True,\n",
    ") -> \"ChessDataset\":\n",
    "    \"\"\"\n",
    "    Load a dataset from a CSV file.\n",
    "\n",
    "    Expected format:\n",
    "    ```\n",
    "    board_fen,move_uci\n",
    "    rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1,e2e4\n",
    "    ...\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    boards = []\n",
    "    moves = []\n",
    "\n",
    "    with open(csv_file, \"r\") as f:\n",
    "        reader = csv.reader(f)\n",
    "\n",
    "        if skip_header:\n",
    "            next(reader)\n",
    "\n",
    "        for row in tqdm(reader, desc=\"Loading dataset\", total=limit):\n",
    "            board_fen, move_uci = row\n",
    "            board = board_fen\n",
    "            boards.append(board)\n",
    "\n",
    "            move = move_uci\n",
    "            moves.append(move)\n",
    "\n",
    "            if limit and len(moves) == limit:\n",
    "                break\n",
    "\n",
    "    return ChessDataset(boards, moves, tokenizer)\n",
    "\n",
    "\n",
    "class ChessDataset(Dataset):\n",
    "    boards: list[str]\n",
    "    moves: list[str]\n",
    "    tokenizer: Callable[[chess.Board], torch.Tensor]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        boards: list[str],\n",
    "        moves: list[str],\n",
    "        tokenizer: Callable[[chess.Board], torch.Tensor],\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.boards = boards\n",
    "        self.moves = moves\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.moves)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Get a training example from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the example to get\n",
    "\n",
    "        Returns:\n",
    "            tuple[torch.Tensor, torch.Tensor]: Tuple containing:\n",
    "                - Board tokens tensor of shape [65]\n",
    "                - Target move probabilities tensor of shape [4096]\n",
    "                - Legal move mask tensor of shape [4096]. 1.0 if the move is legal, 0.0 otherwise.\n",
    "        \"\"\"\n",
    "\n",
    "        board = chess.Board(self.boards[idx])\n",
    "        move = chess.Move.from_uci(self.moves[idx])\n",
    "\n",
    "        board_tokens = self.tokenizer(board)\n",
    "        target = torch.zeros(4096)\n",
    "\n",
    "        target[move.from_square * 64 + move.to_square] = 1.0\n",
    "\n",
    "        legal_move_mask = torch.zeros(4096, dtype=torch.bool)\n",
    "        for move in board.legal_moves:\n",
    "            legal_move_mask[move.from_square * 64 + move.to_square] = True\n",
    "\n",
    "        assert legal_move_mask.sum() > 0, \"No legal moves found\"\n",
    "        assert target.sum() == 1.0, \"Target is not a one-hot vector\"\n",
    "        assert (\n",
    "            legal_move_mask * target\n",
    "        ).sum() > 0, f\"Target is not in the legal move mask. FEN: {board.fen()} MOVE: {self.moves[idx]}\"\n",
    "\n",
    "        return board_tokens, target, legal_move_mask\n",
    "\n",
    "\n",
    "def split_dataset(\n",
    "    dataset: ChessDataset, val_split: float\n",
    ") -> tuple[ChessDataset, ChessDataset]:\n",
    "    n_val = int(len(dataset) * val_split)\n",
    "    train_boards = dataset.boards[:-n_val]\n",
    "    val_boards = dataset.boards[-n_val:]\n",
    "\n",
    "    train_moves = dataset.moves[:-n_val]\n",
    "    val_moves = dataset.moves[-n_val:]\n",
    "\n",
    "    return (\n",
    "        ChessDataset(train_boards, train_moves, dataset.tokenizer),\n",
    "        ChessDataset(val_boards, val_moves, dataset.tokenizer),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|█████████▉| 999/1000 [00:00<00:00, 767841.25it/s]\n"
     ]
    }
   ],
   "source": [
    "all_dataset = load_dataset(\"data_processing/training_data_2.csv\", tokenizer)\n",
    "\n",
    "train_dataset, val_dataset = split_dataset(all_dataset, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    batch_size: int\n",
    "    lr: float\n",
    "    weight_decay: float\n",
    "    warmup_steps: int\n",
    "\n",
    "    checkpoint_path: str\n",
    "    checkpoint_every: int\n",
    "\n",
    "    training_loss_last_n_batches: int\n",
    "    metrics_path: str\n",
    "\n",
    "    device: torch.device\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingMetrics:\n",
    "    loss: float\n",
    "    accuracy: float\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingHistoryPoint:\n",
    "    train: TrainingMetrics\n",
    "    val: TrainingMetrics\n",
    "    step: int\n",
    "    p_epoch: float\n",
    "\n",
    "\n",
    "class TrainingHistory:\n",
    "    data: list[TrainingHistoryPoint]\n",
    "\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "\n",
    "    def add_point(\n",
    "        self, train: TrainingMetrics, val: TrainingMetrics, step: int, p_epoch: float\n",
    "    ):\n",
    "        self.data.append(TrainingHistoryPoint(train, val, step, p_epoch))\n",
    "\n",
    "    def as_csv(self, path: str) -> None:\n",
    "        with open(path, \"w\") as f:\n",
    "            f.write(\n",
    "                \"train_loss,train_accuracy,val_loss,val_accuracy,global_step,p_epoch\\n\"\n",
    "            )\n",
    "            for point in self.data:\n",
    "                f.write(\n",
    "                    f\"{point.train.loss},{point.train.accuracy},{point.val.loss},{point.val.accuracy},{point.step},{point.p_epoch}\\n\"\n",
    "                )\n",
    "\n",
    "\n",
    "class SlidingAverageTrainingMetrics:\n",
    "    n: int\n",
    "    _metrics: list[TrainingMetrics]\n",
    "\n",
    "    def __init__(self, n: int):\n",
    "        self.n = n\n",
    "        self._metrics = []\n",
    "\n",
    "    def add_metric(self, metric: TrainingMetrics):\n",
    "        self._metrics.append(metric)\n",
    "\n",
    "        if len(self._metrics) > self.n:\n",
    "            self._metrics.pop(0)\n",
    "\n",
    "    def get_average(self) -> TrainingMetrics:\n",
    "        return TrainingMetrics(\n",
    "            sum(m.loss for m in self._metrics) / len(self._metrics),\n",
    "            sum(m.accuracy for m in self._metrics) / len(self._metrics),\n",
    "        )\n",
    "\n",
    "\n",
    "class MaskedCrossEntropyLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    A custom loss function for scenarios where some classes are invalid for specific examples.\n",
    "\n",
    "    The loss ignores predictions made for invalid classes and normalizes the remaining\n",
    "    valid logits before computing cross-entropy.\n",
    "\n",
    "    Args:\n",
    "        reduction (str): Specifies the reduction to apply to the output:\n",
    "            'none' | 'mean' | 'sum'. Default: 'mean'\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, reduction=\"mean\"):\n",
    "        super(MaskedCrossEntropyLoss, self).__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(\n",
    "        self, logits: torch.Tensor, targets: torch.Tensor, valid_mask: torch.Tensor\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            logits (torch.Tensor): Raw model output of shape [batch_size, num_classes]\n",
    "            targets (torch.Tensor): Ground truth labels of shape [batch_size]\n",
    "            valid_mask (torch.Tensor): Boolean mask of shape [batch_size, num_classes] where\n",
    "                                      True indicates a valid class and False indicates an invalid class\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The computed loss\n",
    "        \"\"\"\n",
    "\n",
    "        logits = torch.masked_fill(logits, ~valid_mask, 1e-9)\n",
    "\n",
    "        return F.cross_entropy(logits, targets, reduction=self.reduction)\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    model: nn.Module\n",
    "    train_loader: DataLoader\n",
    "    val_loader: DataLoader\n",
    "    config: TrainingConfig\n",
    "\n",
    "    optimizer: torch.optim.Optimizer\n",
    "    scheduler: torch.optim.lr_scheduler.LambdaLR\n",
    "    criterion: MaskedCrossEntropyLoss\n",
    "\n",
    "    train_metrics: SlidingAverageTrainingMetrics\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        model: nn.Module,\n",
    "        train_dataset: ChessDataset,\n",
    "        val_dataset: ChessDataset,\n",
    "        config: TrainingConfig,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=config.batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        self.val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=config.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        self.config = config\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            model.parameters(), lr=config.lr, weight_decay=config.weight_decay\n",
    "        )\n",
    "\n",
    "        self.scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "            self.optimizer,\n",
    "            lambda step: (\n",
    "                min(1.0, step / config.warmup_steps) if config.warmup_steps > 0 else 1.0\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.criterion = MaskedCrossEntropyLoss()\n",
    "\n",
    "        self.train_metrics = SlidingAverageTrainingMetrics(\n",
    "            config.training_loss_last_n_batches\n",
    "        )\n",
    "\n",
    "    def train(self) -> None:\n",
    "        best_val_loss = None\n",
    "        best_val_acc = None\n",
    "        global_step = 0\n",
    "        epoch = 0\n",
    "        history = TrainingHistory()\n",
    "\n",
    "        while True:\n",
    "            n_batches = len(self.train_loader)\n",
    "            pbar = tqdm(self.train_loader, leave=True)\n",
    "\n",
    "            for boards, targets, legal_move_masks in pbar:\n",
    "                boards = boards.to(self.config.device)\n",
    "                targets = targets.to(self.config.device)\n",
    "                legal_move_masks = legal_move_masks.to(self.config.device)\n",
    "\n",
    "                metrics = self.train_batch(boards, targets, legal_move_masks)\n",
    "                self.train_metrics.add_metric(metrics)\n",
    "\n",
    "                # after `config.checkpoint_every` steps, compute validation metrics,\n",
    "                # save the best model, and add the training metrics to the history\n",
    "                if global_step > 0 and global_step % self.config.checkpoint_every == 0:\n",
    "                    val_metrics = self.compute_validation()\n",
    "                    history.add_point(\n",
    "                        self.train_metrics.get_average(),\n",
    "                        val_metrics,\n",
    "                        global_step,\n",
    "                        global_step / n_batches,\n",
    "                    )\n",
    "\n",
    "                    if best_val_loss is None or val_metrics.loss < best_val_loss:\n",
    "                        best_val_loss = val_metrics.loss\n",
    "                        best_val_acc = val_metrics.accuracy\n",
    "                        self.save_checkpoint()\n",
    "                    history.as_csv(self.config.metrics_path)\n",
    "\n",
    "                pbar.set_postfix(\n",
    "                    {\n",
    "                        \"train_loss\": f\"{self.train_metrics.get_average().loss:.4f}\",\n",
    "                        \"train_acc\": f\"{self.train_metrics.get_average().accuracy:.4f}\",\n",
    "                        \"best_val_loss\": (\n",
    "                            f\"{best_val_loss:.4f}\"\n",
    "                            if best_val_loss is not None\n",
    "                            else \"N/A\"\n",
    "                        ),\n",
    "                        \"best_val_acc\": (\n",
    "                            f\"{best_val_acc:.4f}\" if best_val_acc is not None else \"N/A\"\n",
    "                        ),\n",
    "                        \"lr\": f\"{self.optimizer.param_groups[0]['lr']:.6f}\",\n",
    "                        \"global_step\": f\"{global_step:,}\",\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                global_step += 1\n",
    "\n",
    "            epoch += 1\n",
    "\n",
    "    def save_checkpoint(self) -> None:\n",
    "        with open(self.config.checkpoint_path, \"wb\") as f:\n",
    "            torch.save(self.model.state_dict(), f)\n",
    "\n",
    "    def train_batch(\n",
    "        self,\n",
    "        boards: torch.Tensor,\n",
    "        targets: torch.Tensor,\n",
    "        legal_move_masks: torch.Tensor,\n",
    "    ) -> TrainingMetrics:\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        logits = self.model(boards)\n",
    "        loss = self.criterion(logits, targets, legal_move_masks)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.scheduler.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            masked_logits = logits.masked_fill(legal_move_masks == 0, float(\"-inf\"))\n",
    "            _, predicted = torch.max(masked_logits, 1)\n",
    "            _, target_moves = torch.max(targets, 1)\n",
    "            correct = (predicted == target_moves).sum().item()\n",
    "            total = targets.size(0)\n",
    "            accuracy = correct / total\n",
    "\n",
    "        return TrainingMetrics(loss.item(), accuracy)\n",
    "\n",
    "    def compute_validation(self) -> TrainingMetrics:\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            val_loss = 0.0\n",
    "\n",
    "            for boards, targets, legal_move_masks in self.val_loader:\n",
    "                boards = boards.to(self.config.device)\n",
    "                targets = targets.to(self.config.device)\n",
    "                legal_move_masks = legal_move_masks.to(self.config.device)\n",
    "\n",
    "                logits = self.model(boards)\n",
    "                loss = self.criterion(logits, targets, legal_move_masks)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                logits = logits.masked_fill(legal_move_masks == 0, float(\"-inf\"))\n",
    "                _, predicted = torch.max(logits, 1)\n",
    "                _, target_moves = torch.max(targets, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == target_moves).sum().item()\n",
    "\n",
    "            val_loss /= len(self.val_loader)\n",
    "            val_acc = correct / total\n",
    "\n",
    "            return TrainingMetrics(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = TrainingConfig(\n",
    "    batch_size=256,\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    warmup_steps=10_000,\n",
    "    checkpoint_path=\"checkpoint.pth\",\n",
    "    metrics_path=\"metrics.csv\",\n",
    "    checkpoint_every=15_000,\n",
    "\n",
    "    training_loss_last_n_batches=20,\n",
    "    device=get_device(),\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    config=training_config,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffgonext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
